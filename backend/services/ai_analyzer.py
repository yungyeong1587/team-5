"""
AI ë¦¬ë·° ë¶„ì„ê¸° (ë…ë¦½ ì‹¤í–‰)

ì›¹ì„œë²„ì—ì„œ subprocessë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.
ì…ë ¥: JSON (stdin ë˜ëŠ” íŒŒì¼)
ì¶œë ¥: JSON (stdout)

ì‚¬ìš©ë²•:
    python ai_analyzer.py < reviews.json
    ë˜ëŠ”
    python ai_analyzer.py --input reviews.json --output result.json
"""
import sys
import json
import argparse
from pathlib import Path
import logging
import io

# ğŸ”¥ subprocessì—ì„œ ì‹¤í–‰ë˜ë¯€ë¡œ ìì²´ ë¡œê¹… ì„¤ì • í•„ìš”!
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler(sys.stderr)]
)
sys.stderr.flush()
sys.stdin = io.TextIOWrapper(sys.stdin.buffer, encoding='utf-8')
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
logger = logging.getLogger(__name__)


class ReviewAIAnalyzer:
    """ë¦¬ë·° AI ë¶„ì„ê¸° (KcELECTRA ê¸°ë°˜)"""
    
    def __init__(self, model_path="ai_models"):
        """
        AI ëª¨ë¸ ì´ˆê¸°í™”
        
        Args:
            model_path: ëª¨ë¸ íŒŒì¼ë“¤ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ (project/ai_models)
        """

        # í˜„ì¬ íŒŒì¼(ai_analyzer.py)ì˜ ì ˆëŒ€ ê²½ë¡œ
        current_file = Path(__file__).resolve()

        # project/backend/services â†’ project/backend â†’ project/
        project_root = current_file.parent.parent.parent

        # ëª¨ë¸ í´ë” ì ˆëŒ€ê²½ë¡œ êµ¬ì„±
        self.model_path = project_root / model_path

        # ë””ë²„ê·¸ ì¶œë ¥
        print(f"[AI_ANALYZER] BASE FILE: {current_file}", file=sys.stderr)
        print(f"[AI_ANALYZER] PROJECT ROOT: {project_root}", file=sys.stderr)
        print(f"[AI_ANALYZER] MODEL PATH: {self.model_path}", file=sys.stderr)

        self.model = None
        self.tokenizer = None
        self.device = None
        
        logger.info(f"AI ë¶„ì„ê¸° ì´ˆê¸°í™”: {model_path}")

    def load_model(self):
        """
        AI ëª¨ë¸ ë¡œë“œ (KcELECTRA)
        
        ëª¨ë¸ ì •ë³´:
        - ë² ì´ìŠ¤: beomi/KcELECTRA-base-v2022
        - í´ë˜ìŠ¤: 0=ë¹„ì‹ ë¢°, 1=ì‹ ë¢°
        - max_length: 128
        """
        try:
            import torch
            from transformers import AutoModelForSequenceClassification, AutoTokenizer
            
            logger.info("AI ëª¨ë¸ ë¡œë”© ì¤‘...")
            # 1. ë””ë°”ì´ìŠ¤ ì„¤ì •
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            logger.info(f"ë””ë°”ì´ìŠ¤: {self.device}")
        
            # 2. í† í¬ë‚˜ì´ì € ë¡œë“œ
            self.tokenizer = AutoTokenizer.from_pretrained(
                str(self.model_path),
                local_files_only=True
            )
            
            # 3. ëª¨ë¸ ë¡œë“œ
            self.model = AutoModelForSequenceClassification.from_pretrained(
                str(self.model_path),
                local_files_only=True
            )
            
            # 4. ëª¨ë¸ì„ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
            self.model.to(self.device)
            
            # 5. í‰ê°€ ëª¨ë“œ ì„¤ì •
            self.model.eval()
            
            logger.info("âœ… AI ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
            logger.info(f"   - ëª¨ë¸: KcELECTRA")
            logger.info(f"   - í´ë˜ìŠ¤: 2ê°œ (0=ë¹„ì‹ ë¢°, 1=ì‹ ë¢°)")
            logger.info(f"   - ë””ë°”ì´ìŠ¤: {self.device}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def preprocess_reviews(self, reviews):
        """
        ë¦¬ë·° ë°ì´í„° ì „ì²˜ë¦¬
        
        Args:
            reviews: ë¦¬ë·° ë¦¬ìŠ¤íŠ¸ [{"text": "...", "rating": 5}, ...]
        
        Returns:
            ì „ì²˜ë¦¬ëœ ë°ì´í„°
        """
        processed = []
        
        for review in reviews:
            text = review.get('text', '')
            rating = review.get('rating', 0)
            
            # í…ìŠ¤íŠ¸ ì •ì œ
            text = text.strip()
            
            if text:
                processed.append({
                    'text': text,
                    'rating': rating,
                    'length': len(text)
                })
        
        logger.info(f"ì „ì²˜ë¦¬ ì™„ë£Œ: {len(processed)}ê°œ ë¦¬ë·°")
        return processed
    
    def analyze_reviews(self, reviews):
        """
        ë¦¬ë·° ë¶„ì„ ìˆ˜í–‰ (ì‹¤ì œ AI ëª¨ë¸ ì‚¬ìš©)
        
        Args:
            reviews: ì „ì²˜ë¦¬ëœ ë¦¬ë·° ë¦¬ìŠ¤íŠ¸
        
        Returns:
            ë¶„ì„ ê²°ê³¼ {
                'verdict': 'safe' | 'suspicious' | 'malicious',
                'confidence': float (0-100),
                'details': {...}
            }
        """
        try:
            import torch
            import torch.nn.functional as F
            
            logger.info(f"AI ë¶„ì„ ì‹œì‘: {len(reviews)}ê°œ ë¦¬ë·°")
            
            # 1. í…ìŠ¤íŠ¸ ì¶”ì¶œ
            texts = [r['text'] for r in reviews]
            
            # 2. ë°°ì¹˜ ì²˜ë¦¬ (ë©”ëª¨ë¦¬ íš¨ìœ¨)
            batch_size = 32
            all_trust_scores = []
            
            for i in range(0, len(texts), batch_size):
                batch_texts = texts[i:i+batch_size]
                
                # í† í¬ë‚˜ì´ì§• (max_length=128)
                inputs = self.tokenizer(
                    batch_texts,
                    return_tensors="pt",
                    truncation=True,
                    max_length=128,  # â† AI íŒŒíŠ¸ í™•ì¸ë¨
                    padding=True
                ).to(self.device)
                
                # ì¶”ë¡ 
                with torch.no_grad():
                    outputs = self.model(**inputs)
                    
                    # Softmaxë¡œ í™•ë¥  ê³„ì‚°
                    probs = F.softmax(outputs.logits, dim=-1)
                    
                    # í´ë˜ìŠ¤ 1 (ì‹ ë¢°) í™•ë¥  ì¶”ì¶œ
                    trust_probs = probs[:, 1].cpu().tolist()
                    all_trust_scores.extend(trust_probs)
                
                logger.debug(f"ë°°ì¹˜ {i//batch_size + 1}: {len(batch_texts)}ê°œ ì²˜ë¦¬")
            
            # 3. ê²°ê³¼ ì§‘ê³„
            avg_trust = sum(all_trust_scores) / len(all_trust_scores)
            max_trust = max(all_trust_scores)
            min_trust = min(all_trust_scores)
            
            # 4. íŒì • (í‰ê·  ì‹ ë¢°ë„ ê¸°ë°˜)
            # avg_trust > 0.7 â†’ safe (ì‹ ë¢°ë„ ë†’ìŒ)
            # 0.3 <= avg_trust <= 0.7 â†’ suspicious (ì˜ì‹¬ìŠ¤ëŸ¬ì›€)
            # avg_trust < 0.3 â†’ malicious (ì‹ ë¢°ë„ ë‚®ìŒ, ì¡°ì‘ ê°€ëŠ¥ì„±)
            
            if avg_trust > 0.7:
                verdict = 'safe'
                confidence = avg_trust * 100  # 70~100%
            elif avg_trust >= 0.3:
                verdict = 'suspicious'
                confidence = 50 + (avg_trust - 0.3) * 125  # 50~100%
            else:
                verdict = 'malicious'
                confidence = 90 + (1 - avg_trust / 0.3) * 10  # 90~100% (ìœ„í—˜ë„)
            
            # 5. ê²°ê³¼ ë°˜í™˜
            result = {
                'verdict': verdict,
                'confidence': round(confidence, 2),
                'details': {
                    'avg_trust_score': round(avg_trust, 4),
                    'max_trust_score': round(max_trust, 4),
                    'min_trust_score': round(min_trust, 4),
                    'total_reviews': len(reviews),
                    'device': str(self.device),
                    'model': 'KcELECTRA-base-v2022'
                }
            }
            
            logger.info(f"âœ… AI ë¶„ì„ ì™„ë£Œ: {verdict} (ì‹ ë¢°ë„ í‰ê· : {avg_trust:.4f})")

            return result
            
        except Exception as e:
            logger.error(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            raise
    
    def run(self, reviews):
        """
        ì „ì²´ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        
        Args:
            reviews: ì›ë³¸ ë¦¬ë·° ë¦¬ìŠ¤íŠ¸
        
        Returns:
            ë¶„ì„ ê²°ê³¼
        """
        # 1. ëª¨ë¸ ë¡œë“œ (í•„ìš”ì‹œ)
        if self.model is None:
            if not self.load_model():
                return {
                    'verdict': 'error',
                    'confidence': 0,
                    'error': 'ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨'
                }
        
        # 2. ì „ì²˜ë¦¬
        processed_reviews = self.preprocess_reviews(reviews)
        
        if not processed_reviews:
            return {
                'verdict': 'error',
                'confidence': 0,
                'error': 'ë¶„ì„í•  ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤'
            }
        
        # 3. ë¶„ì„
        result = self.analyze_reviews(processed_reviews)
        
        return result


def main():
    """ë©”ì¸ í•¨ìˆ˜ (CLI ì‹¤í–‰)"""
    parser = argparse.ArgumentParser(description='ë¦¬ë·° AI ë¶„ì„ê¸° (KcELECTRA)')
    parser.add_argument('--input', type=str, help='ì…ë ¥ JSON íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--output', type=str, help='ì¶œë ¥ JSON íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--model', type=str, default='ai_models', help='ëª¨ë¸ ë””ë ‰í† ë¦¬')
    
    args = parser.parse_args()
    
    try:
        # 1. ì…ë ¥ ì½ê¸°
        if args.input:
            # íŒŒì¼ì—ì„œ ì½ê¸°
            with open(args.input, 'r', encoding='utf-8') as f:
                data = json.load(f)
        else:
            # stdinì—ì„œ ì½ê¸°
            data = json.load(sys.stdin)
        
        reviews = data.get('reviews', [])
        
        if not reviews:
            raise ValueError("ë¦¬ë·° ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
        
        # 2. ë¶„ì„ ì‹¤í–‰
        analyzer = ReviewAIAnalyzer(model_path=args.model)
        result = analyzer.run(reviews)
        
        # 3. ê²°ê³¼ ì¶œë ¥
        output_data = {
            'success': True,
            'result': result
        }
        
        if args.output:
            # íŒŒì¼ì— ì €ì¥
            with open(args.output, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, ensure_ascii=False, indent=2)
            logger.info(f"ê²°ê³¼ ì €ì¥: {args.output}")
        else:
            # stdoutì— ì¶œë ¥
            print(json.dumps(output_data, ensure_ascii=False))
        
        sys.exit(0)
        
    except Exception as e:
        logger.error(f"ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        
        error_data = {
            'success': False,
            'error': str(e)
        }
        
        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                json.dump(error_data, f, ensure_ascii=False, indent=2)
        else:
            print(json.dumps(error_data, ensure_ascii=False))
        
        sys.exit(1)


if __name__ == "__main__":
    main()