"""
ë¶„ì„ ì„œë¹„ìŠ¤ (ë…ë¦½ì )
ë¦¬ë·° ë¶„ì„ ì „ë‹´ (í¬ë¡¤ë§ì€ MusinsaCrawlerì— ìœ„ìž„)
"""
from sqlalchemy.orm import Session
from models.analysis import Analysis
from services.musinsa_api_crawler import MusinsaCrawler
import logging
import random # âœ… ëžœë¤ ì¶”ì¶œìš© ëª¨ë“ˆ ì¶”ê°€
import json
import subprocess
import time
import sys
import os

logger = logging.getLogger(__name__)

class AnalysisService:
    """ë¶„ì„ ì„œë¹„ìŠ¤"""
    
    @staticmethod
    def create_analysis(db: Session, review_url: str) -> Analysis:
        """ë¶„ì„ ìš”ì²­ ìƒì„±"""
        analysis = Analysis(
            review_url=review_url,
            status='queued'
        )
        db.add(analysis)
        db.commit()
        db.refresh(analysis)
        return analysis
    
    @staticmethod
    def get_analysis(db: Session, analysis_id: int) -> Analysis:
        """ë¶„ì„ ìš”ì²­ ì¡°íšŒ"""
        return db.query(Analysis).filter(Analysis.analysis_id == analysis_id).first()
    
    @staticmethod
    def list_analyses(
        db: Session,
        status: str = None,
        skip: int = 0,
        limit: int = 10
    ) -> list:
        """ë¶„ì„ ëª©ë¡ ì¡°íšŒ"""
        query = db.query(Analysis)
        
        if status:
            query = query.filter(Analysis.status == status)
        
        analyses = query.order_by(Analysis.created_at.desc()).offset(skip).limit(limit).all()
        return [analysis.to_dict() for analysis in analyses]
    
    @staticmethod
    def update_analysis_status(
        db: Session, 
        analysis_id: int, 
        status: str,
        verdict: str = None,
        confidence: float = None,
        error_message: str = None,
        review_count: int = None,
        top_reviews: list = None,  
        worst_reviews: list = None,
        summary: str = None
    ):
        """ë¶„ì„ ìƒíƒœ ì—…ë°ì´íŠ¸"""
        analysis = db.query(Analysis).filter(Analysis.analysis_id == analysis_id).first()
        if analysis:
            analysis.status = status
            if verdict:
                analysis.verdict = verdict
            if confidence is not None:
                analysis.confidence = confidence
            if error_message:
                analysis.error_message = error_message
            if review_count is not None:
                analysis.review_count = review_count
            
            # âœ… [DB ì €ìž¥] ë¦¬ë·° ìƒ˜í”Œ ë¦¬ìŠ¤íŠ¸ ì €ìž¥
            if top_reviews is not None:
                analysis.top_reviews = top_reviews
            if worst_reviews is not None:
                analysis.worst_reviews = worst_reviews
            if summary: analysis.summary = summary
                
            db.commit()
            db.refresh(analysis)
        return analysis
    
    @staticmethod
    async def analyze_with_ai(reviews: list, analysis_id: int, db: Session) -> dict:
        """
        AI ì„œë²„ë¡œ ë¦¬ë·° ë¶„ì„ ìš”ì²­ (subprocess ì‹¤í–‰)
        """
        try:
            logger.info(f"[Analysis {analysis_id}] ========================================")
            logger.info(f"[Analysis {analysis_id}] ðŸ¤– AI ë¶„ì„ ì‹œìž‘")
            logger.info(f"[Analysis {analysis_id}] ========================================")
            logger.info(f"[Analysis {analysis_id}] ðŸ“Š ë¦¬ë·° ê°œìˆ˜: {len(reviews)}ê°œ")
            
            # 1. ìž…ë ¥ ë°ì´í„° ì¤€ë¹„
            logger.info(f"[Analysis {analysis_id}] ðŸ“ Step 1: ìž…ë ¥ ë°ì´í„° ì¤€ë¹„")
            input_data = {
                'reviews': reviews,
                'analysis_id': analysis_id
            }
            input_json = json.dumps(input_data, ensure_ascii=False)
            logger.info(f"[Analysis {analysis_id}] âœ… ìž…ë ¥ ë°ì´í„° í¬ê¸°: {len(input_json)} bytes")
            
            # 2. AI ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
            logger.info(f"[Analysis {analysis_id}] ðŸš€ Step 2: AI ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì¤‘...")
            logger.info(f"[Analysis {analysis_id}] ëª…ë ¹: python services/ai_analyzer.py")
            
            start_time = time.time()

            # [ìˆ˜ì •ë¨] ìœˆë„ìš° í™˜ê²½ ì¸ì½”ë”© ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ í™˜ê²½ë³€ìˆ˜ ì„¤ì •
            my_env = os.environ.copy()
            my_env["PYTHONIOENCODING"] = "utf-8"

            process = subprocess.run(
                [sys.executable, 'services/ai_analyzer.py'],
                input=input_json,
                capture_output=True,
                text=True,
                encoding='utf-8', 
                env=my_env,       # [ìˆ˜ì •ë¨] ì—¬ê¸°ì— env ì˜µì…˜ ì¶”ê°€!
                timeout=300,      
                bufsize=1
            )
            
            elapsed_time = time.time() - start_time
            logger.info(f"[Analysis {analysis_id}] â±ï¸  ì‹¤í–‰ ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
            
            # 3. ê²°ê³¼ íŒŒì‹±
            if process.returncode != 0:
                logger.error(f"[Analysis {analysis_id}] âŒ AI ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨!")
                logger.error(f"[Analysis {analysis_id}] STDERR: {process.stderr}")
                raise Exception(f"AI ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {process.stderr}")
            
            output_data = json.loads(process.stdout)
            
            if not output_data.get('success'):
                error_msg = output_data.get('error', 'AI ë¶„ì„ ì‹¤íŒ¨')
                raise Exception(error_msg)
            
            ai_result = output_data['result']
            verdict = ai_result.get('verdict')
            confidence = ai_result.get('confidence', 0)
            
            logger.info(f"[Analysis {analysis_id}] âœ… AI ë¶„ì„ ì™„ë£Œ: {verdict} ({confidence}%)")
            
            return {
                'success': True,
                'verdict': verdict,
                'confidence': confidence,
                'details': ai_result.get('details', {}),
                'message': 'AI ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.'
            }
            
        except subprocess.TimeoutExpired:
            logger.error(f"[Analysis {analysis_id}] â±ï¸  AI ë¶„ì„ íƒ€ìž„ì•„ì›ƒ")
            AnalysisService.update_analysis_status(
                db, analysis_id, 'failed',
                error_message='AI ë¶„ì„ ì‹œê°„ ì´ˆê³¼'
            )
            return {'success': False, 'message': 'AI ë¶„ì„ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤.'}
            
        except Exception as e:
            logger.error(f"[Analysis {analysis_id}] âŒ AI ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            AnalysisService.update_analysis_status(
                db, analysis_id, 'failed',
                error_message=f'AI ë¶„ì„ ì˜¤ë¥˜: {str(e)}'
            )
            return {'success': False, 'message': f'AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}

    @staticmethod
    async def process_analysis(analysis_id: int, review_url: str, db: Session) -> dict:
        """
        ì „ì²´ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        """
        try:
            logger.info(f"")
            logger.info(f"{'='*70}")
            logger.info(f"[Analysis {analysis_id}] ðŸš€ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹œìž‘")
            logger.info(f"{'='*70}")
            
            # 1. ìƒíƒœ ì—…ë°ì´íŠ¸
            AnalysisService.update_analysis_status(db, analysis_id, 'processing')
            
            # 2. í¬ë¡¤ë§
            logger.info(f"[Analysis {analysis_id}] ðŸ•·ï¸  Step 1/3: ë¦¬ë·° í¬ë¡¤ë§")
            crawl_start = time.time()
            
            crawler = MusinsaCrawler()
            crawl_result = crawler.crawl_reviews(product_url=review_url, max_reviews=100)
            
            crawl_time = time.time() - crawl_start
            
            if not crawl_result['success']:
                raise Exception(crawl_result['message'])
            
            logger.info(f"[Analysis {analysis_id}] âœ… í¬ë¡¤ë§ ì™„ë£Œ ({crawl_result['raw_count']}ê°œ)")

            logger.info(f"[Analysis {analysis_id}] ðŸŽ² ë¦¬ë·° ìƒ˜í”Œë§ ë° ë°ì´í„° í‘œì¤€í™”")
            
            all_reviews = crawl_result['reviews']
            
            # ==================================================================
            # âœ… [í•µì‹¬ ìˆ˜ì •] ë°ì´í„° í‘œì¤€í™” í•¨ìˆ˜ (ì´ë¦„í‘œ í†µì¼)
            # ==================================================================
            def normalize_review(r):
                # í¬ë¡¤ëŸ¬ê°€ ì£¼ëŠ” í‚¤ê°€ ë¬´ì—‡ì´ë“  í™”ë©´ì—ì„œ ì“°ëŠ” 'content', 'rating', 'date'ë¡œ ë³€í™˜
                content = r.get('content') or r.get('message') or r.get('review_body') or r.get('text') or "ë‚´ìš© ì—†ìŒ"
                date = r.get('date') or r.get('reg_date') or r.get('created_at') or ""
                rating = r.get('rating', 0)
                
                return {
                    "content": str(content).strip(),  # ê°•ì œë¡œ ë¬¸ìžì—´ ë³€í™˜
                    "rating": int(rating),            # ê°•ì œë¡œ ì •ìˆ˜ ë³€í™˜
                    "date": str(date),
                    "author": r.get('author', '***')
                }
            # ==================================================================

            # í‰ì  ê¸°ë°˜ ë¶„ë¥˜
            high_rated_reviews = [r for r in all_reviews if r.get('rating', 0) >= 4]
            low_rated_reviews = [r for r in all_reviews if r.get('rating', 0) <= 2]
            
            # ëžœë¤ ì„žê¸°
            random.shuffle(high_rated_reviews)
            random.shuffle(low_rated_reviews)
            
            # 10ê°œì”© ì¶”ì¶œí•˜ë©´ì„œ ë™ì‹œì— í‘œì¤€í™” ì ìš© (!)
            top_reviews = [normalize_review(r) for r in high_rated_reviews[:10]]
            worst_reviews = [normalize_review(r) for r in low_rated_reviews[:10]]
            
            logger.info(f"[Analysis {analysis_id}] ðŸ‘ ë†’ì€ í‰ì  ìƒ˜í”Œ: {len(top_reviews)}ê°œ")
            
            # âœ… [ë””ë²„ê¹…] ì‹¤ì œë¡œ ë“¤ì–´ê°€ëŠ” ë°ì´í„° í™•ì¸ (ë¡œê·¸ í™•ì¸ìš©)
            if top_reviews:
                logger.info(f"[DEBUG] ì €ìž¥ë  ë¦¬ë·° ë°ì´í„° ì˜ˆì‹œ: {top_reviews[0]}")
            
            # 3. AI ë¶„ì„
            logger.info(f"[Analysis {analysis_id}] ðŸ¤– Step 2/3: AI ë¶„ì„")
            ai_start = time.time()
            
            ai_result = await AnalysisService.analyze_with_ai(
                reviews=crawl_result['reviews'],
                analysis_id=analysis_id,
                db=db
            )
            
            ai_time = time.time() - ai_start
            
            if not ai_result['success']:
                raise Exception(ai_result['message'])

            # 4. ìµœì¢… ì €ìž¥
            logger.info(f"[Analysis {analysis_id}] ðŸ’¾ Step 3/3: ê²°ê³¼ ì €ìž¥ ë° ì™„ë£Œ")
            
            # AI ê²°ê³¼ì—ì„œ ìš”ì•½ ê°€ì ¸ì˜¤ê¸°
            ai_summary = ai_result.get('details', {}).get('summary', 'ë¦¬ë·° ìš”ì•½ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.')

            AnalysisService.update_analysis_status(
                db, analysis_id, 'completed',
                verdict=ai_result['verdict'],
                confidence=ai_result['confidence'],
                review_count=len(crawl_result['reviews']),
                top_reviews=top_reviews,      # âœ… í‘œì¤€í™”ëœ ë°ì´í„° ì €ìž¥
                worst_reviews=worst_reviews,  # âœ… í‘œì¤€í™”ëœ ë°ì´í„° ì €ìž¥
                summary=ai_summary
            )
            
            total_time = crawl_time + ai_time
            analysis = AnalysisService.get_analysis(db, analysis_id)
            
            logger.info(f"{'='*70}")
            logger.info(f"[Analysis {analysis_id}] ðŸŽ‰ ë¶„ì„ ì™„ë£Œ! (ì†Œìš”ì‹œê°„: {total_time:.2f}ì´ˆ)")
            logger.info(f"{'='*70}")
            
            return {
                'success': True,
                'message': 'ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.',
                'analysis_id': analysis.analysis_id,
                'status': analysis.status,
                'verdict': analysis.verdict,
                'confidence': float(analysis.confidence) if analysis.confidence else None,
                'review_count': analysis.review_count,
                'top_reviews': top_reviews,      
                'worst_reviews': worst_reviews,
                'summary': ai_summary
            }
            
        except Exception as e:
            logger.error(f"[Analysis {analysis_id}] âŒ íŒŒì´í”„ë¼ì¸ ì—ëŸ¬: {str(e)}")
            AnalysisService.update_analysis_status(db, analysis_id, 'failed', error_message=str(e))
            return {
                'success': False,
                'message': f'ì˜¤ë¥˜ ë°œìƒ: {str(e)}',
                'analysis_id': analysis_id,
                'status': 'failed'
            }