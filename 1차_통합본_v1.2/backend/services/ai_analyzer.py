"""
AI ë¦¬ë·° ë¶„ì„ê¸° (ë…ë¦½ ì‹¤í–‰)
ì…ë ¥: JSON (stdin ë˜ëŠ” íŒŒì¼)
ì¶œë ¥: JSON (stdout)
"""
import re
import sys
import json
import argparse
from pathlib import Path
import logging
import io
import joblib

# í•œê¸€ ì¸ì½”ë”© ì„¤ì •
sys.stderr.flush()
sys.stdin = io.TextIOWrapper(sys.stdin.buffer, encoding='utf-8')
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler(sys.stderr)]
)
logger = logging.getLogger(__name__)

class ReviewAIAnalyzer:
    """ë¦¬ë·° AI ë¶„ì„ê¸° (KcELECTRA + Random Forest)"""
    
    def __init__(self, model_path="ai_models", retrain_model_path="backend/scripts/ai_models_retrained"):
        # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ ëª¨ë¸ ê²½ë¡œ ì„¤ì •
        current_file = Path(__file__).resolve()
        project_root = current_file.parent.parent.parent
        
        self.base_model_path = project_root / model_path
        self.retrain_root = project_root / retrain_model_path
        
        # ìµœì‹  ëª¨ë¸ ê²½ë¡œ
        self.model_path = self.get_latest_model_path()
        
        # RandomForestëŠ” í•­ìƒ ai_modelsì— ê³ ì •
        self.rf_model_path = project_root / "ai_models" / "random_forest.pkl"

        self.model = None
        self.rf_model = None
        self.tokenizer = None
        self.device = None
        
        logger.info(f"="*60)
        logger.info(f"AI ë¶„ì„ê¸° ì´ˆê¸°í™”")
        logger.info(f"  KcELECTRA: {self.model_path}")
        logger.info(f"  RandomForest: {self.rf_model_path}")
        logger.info(f"="*60)

    def get_latest_model_path(self):
        """ì¬í•™ìŠµëœ ëª¨ë¸ ì¤‘ ê°€ì¥ ìµœì‹  ë²„ì „ì„ ìë™ ì„ íƒ"""
        try:
            if not self.retrain_root.exists():
                logger.info("ğŸ“‚ ì¬í•™ìŠµ í´ë” ì—†ìŒ â†’ ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©")
                return self.base_model_path

            # ì¬í•™ìŠµ í´ë” ì•ˆì˜ model_YYYYMMDD_HHMMSS ê°™ì€ í´ë” ëª¨ë‘ ê°€ì ¸ì˜¤ê¸°
            model_dirs = [
                d for d in self.retrain_root.iterdir()
                if d.is_dir() and re.match(r"model_\d{8}_\d{6}", d.name)
            ]

            if not model_dirs:
                logger.info("ğŸ“‚ ì¬í•™ìŠµ ëª¨ë¸ ì—†ìŒ â†’ ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©")
                return self.base_model_path

            # ê°€ì¥ ìµœê·¼ ëª¨ë¸ ì„ íƒ
            latest = max(model_dirs, key=lambda d: d.stat().st_mtime)

            logger.info(f"âœ… ìµœì‹  ì¬í•™ìŠµ ëª¨ë¸ ì„ íƒ: {latest.name}")
            return latest

        except Exception as e:
            logger.error(f"âŒ ìµœì‹  ëª¨ë¸ íƒìƒ‰ ì‹¤íŒ¨: {e}")
            return self.base_model_path

    def load_model(self):
        """AI ëª¨ë¸ ë¡œë“œ"""
        try:
            import torch
            from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig
            
            logger.info("="*60)
            logger.info("AI ëª¨ë¸ ë¡œë”© ì‹œì‘...")
            logger.info("="*60)
            
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            logger.info(f"ğŸ–¥ï¸  ë””ë°”ì´ìŠ¤: {self.device}")
            
            # KcELECTRA ë¡œë“œ
            logger.info("ğŸ“‹ Config ë¡œë”©...")
            config = AutoConfig.from_pretrained(str(self.model_path), local_files_only=True)
            
            logger.info("ğŸ“ Tokenizer ë¡œë”©...")
            self.tokenizer = AutoTokenizer.from_pretrained(str(self.model_path), local_files_only=True)
            
            logger.info("ğŸ¤– KcELECTRA ë¡œë”©...")
            self.model = AutoModelForSequenceClassification.from_pretrained(
                str(self.model_path),
                config=config,
                local_files_only=True
            )
            self.model.to(self.device)
            self.model.eval()
            
            logger.info(f"âœ… KcELECTRA ë¡œë”© ì™„ë£Œ")

        except Exception as e:
            logger.error(f"âŒ KcELECTRA ë¡œë”© ì‹¤íŒ¨: {e}")
            return False
    
        # RandomForest ë¡œë“œ (ì„ íƒì )
        try:
            if self.rf_model_path.exists():
                self.rf_model = joblib.load(str(self.rf_model_path))
                logger.info("âœ… RandomForest ë¡œë”© ì™„ë£Œ")
                logger.info(f"   - Features: {self.rf_model.n_features_in_}")
            else:
                logger.warning(f"âš ï¸ RandomForest íŒŒì¼ ì—†ìŒ: {self.rf_model_path}")
                logger.warning("âš ï¸ KcELECTRA ë‹¨ë… ëª¨ë“œë¡œ ì‘ë™")
                self.rf_model = None
        except Exception as e:
            logger.error(f"âš ï¸ RandomForest ë¡œë”© ì‹¤íŒ¨: {e}")
            logger.warning("âš ï¸ KcELECTRA ë‹¨ë… ëª¨ë“œë¡œ ì‘ë™")
            self.rf_model = None
        
        logger.info("="*60)
        if self.rf_model:
            logger.info("âœ… 2ë‹¨ê³„ ëª¨ë“œ (KcELECTRA + RandomForest)")
        else:
            logger.info("âœ… 1ë‹¨ê³„ ëª¨ë“œ (KcELECTRA ë‹¨ë…)")
        logger.info("="*60)
        
        return True

    def preprocess_reviews(self, reviews):
        """ì „ì²˜ë¦¬: í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ë¦¬ë·°ë§Œ ì¶”ì¶œ"""
        processed = []
        for review in reviews:
            # textë‚˜ content í‚¤ê°€ ì„ì—¬ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë‘˜ ë‹¤ í™•ì¸
            text = review.get('text', '') or review.get('content', '')
            if not text:
                continue
            
            # ì›ë³¸ ë°ì´í„° ë³´ì¡´í•˜ë©° text í•„ë“œ í†µì¼
            item = review.copy()
            item['text'] = text.strip()
            processed.append(item)
        
        logger.info(f"ğŸ“Š ì „ì²˜ë¦¬ ì™„ë£Œ: {len(processed)}ê°œ ë¦¬ë·°")
        return processed
    
    def analyze_reviews(self, reviews):
        """ë¦¬ë·° ë¶„ì„ ìˆ˜í–‰ ë° ê°œë³„ ì ìˆ˜ ë§ˆí‚¹"""
        try:
            import torch
            import torch.nn.functional as F
            
            logger.info("="*60)
            logger.info(f"AI ë¶„ì„ ì‹œì‘: {len(reviews)}ê°œ ë¦¬ë·°")
            logger.info("="*60)
            
            texts = [r['text'] for r in reviews]
            batch_size = 32
            all_trust_scores = []
            
            # ========================================
            # Step 1: KcELECTRA í…ìŠ¤íŠ¸ ë¶„ì„
            # ========================================
            logger.info("[Step 1] KcELECTRA ë¶„ì„ ì¤‘...")
            
            for i in range(0, len(texts), batch_size):
                batch_texts = texts[i:i+batch_size]
                
                inputs = self.tokenizer(
                    batch_texts,
                    return_tensors="pt",
                    truncation=True,
                    max_length=128,
                    padding=True
                ).to(self.device)
                
                with torch.no_grad():
                    outputs = self.model(**inputs)
                    probs = F.softmax(outputs.logits, dim=-1)
                    # 1ë²ˆ í´ë˜ìŠ¤(ì‹ ë¢°/ê¸ì •) í™•ë¥  ì¶”ì¶œ
                    trust_probs = probs[:, 1].cpu().tolist()
                    all_trust_scores.extend(trust_probs)
            
            logger.info(f"âœ… KcELECTRA ë¶„ì„ ì™„ë£Œ: {len(all_trust_scores)}ê°œ ì ìˆ˜")
            
            # ========================================
            # Step 2: RandomForest 2ë‹¨ê³„ íŒë‹¨ (ìˆì„ ê²½ìš°)
            # ========================================
            if self.rf_model is not None:
                logger.info("[Step 2] RandomForest ë¶„ì„ ì¤‘...")
                
                import numpy as np

                # ëª¨ë¸ ì…ë ¥ feature ìˆ˜ ìë™ ê°ì§€
                n_features = self.rf_model.n_features_in_

                rf_inputs = []
                for i, r in enumerate(reviews):
                    electra = all_trust_scores[i]
                    rating = r.get("rating", 0)

                    # Feature ìˆ˜ì— ë§ê²Œ ì…ë ¥ êµ¬ì„±
                    if n_features == 5:
                        features = [electra, rating, 0, 0, 0]  # [ELECTRA, ë³„ì , ìœ ì €ë ˆë²¨, ë„ì›€, ë‹µê¸€]
                    elif n_features == 4:
                        features = [electra, rating, 0, 0]
                    elif n_features == 2:
                        features = [electra, rating]
                    else:
                        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” RF ì…ë ¥ feature ìˆ˜: {n_features}")

                    rf_inputs.append(features)

                rf_inputs = np.array(rf_inputs)

                # RandomForest ì˜ˆì¸¡
                rf_probs = self.rf_model.predict_proba(rf_inputs)
                final_scores = rf_probs[:, 1].tolist()   # ì‹ ë¢° í™•ë¥ 
                
                logger.info(f"âœ… RandomForest ë¶„ì„ ì™„ë£Œ")
            else:
                # RandomForest ì—†ìœ¼ë©´ KcELECTRA ì ìˆ˜ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                logger.info("[Step 2] RandomForest ì—†ìŒ â†’ KcELECTRA ì ìˆ˜ ì‚¬ìš©")
                final_scores = all_trust_scores

            # ========================================
            # Step 3: ê°œë³„ ë¦¬ë·°ì— ì ìˆ˜ ë° ë¼ë²¨/ìƒ‰ìƒ ë¶€ì°©
            # ========================================
            enriched_reviews = []
            for i, review in enumerate(reviews):
                score = final_scores[i] * 100  # 0~100ì  ë³€í™˜

                # ë¼ë²¨ë§ ë° ìƒ‰ìƒ ê²°ì •
                if score >= 76:
                    label = "ë§¤ìš° ë„ì›€ë¨"
                    color = "status-green"
                elif score >= 36:
                    label = "ë¶€ë¶„ì ìœ¼ë¡œ ë„ì›€ë¨"
                    color = "status-orange"
                else:
                    label = "ë„ì›€ ì•ˆë¨"
                    color = "status-red"

                # ë¦¬ë·° ë°ì´í„°ì— ì ìˆ˜ ë° ë¼ë²¨ ì¶”ê°€
                review["reliability_score"] = round(score, 1)
                review["analysis_label"] = label
                review["color_class"] = color

                enriched_reviews.append(review)
            
            # ========================================
            # Step 4: ì „ì²´ í†µê³„ ë° íŒì •
            # ========================================
            avg_trust = sum(final_scores) / len(final_scores) if final_scores else 0
            
            # ì „ì²´ íŒì • (ê¸°ì¡´ ì½”ë“œì™€ í˜¸í™˜)
            if avg_trust > 0.7:
                verdict = 'safe'
                verdict_kr = 'ì‹ ë¢°í•  ë§Œí•¨'
            elif avg_trust >= 0.3:
                verdict = 'suspicious'
                verdict_kr = 'ì˜ì‹¬ìŠ¤ëŸ¬ì›€'
            else:
                verdict = 'malicious'
                verdict_kr = 'ì‹ ë¢°í•˜ê¸° ì–´ë ¤ì›€'

            confidence = round(avg_trust * 100, 2)
            
            result = {
                'verdict': verdict,
                'verdict_kr': verdict_kr,
                'confidence': confidence,
                'enriched_reviews': enriched_reviews,
                'details': {
                    'avg_trust_score': round(avg_trust, 4),
                    'avg_electra_score': round(sum(all_trust_scores)/len(all_trust_scores), 4),
                    'total_reviews': len(reviews),
                    'model_mode': 'KcELECTRA + RandomForest' if self.rf_model else 'KcELECTRA Only'
                }
            }
            
            logger.info("="*60)
            logger.info(f"âœ… AI ë¶„ì„ ì™„ë£Œ")
            logger.info(f"   - íŒì •: {verdict_kr}")
            logger.info(f"   - ì‹ ë¢°ë„: {confidence}%")
            logger.info(f"   - ëª¨ë“œ: {result['details']['model_mode']}")
            logger.info("="*60)
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            raise
    
    def run(self, reviews):
        if self.model is None:
            if not self.load_model():
                return {'verdict': 'error', 'confidence': 0, 'error': 'ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨'}
        
        processed_reviews = self.preprocess_reviews(reviews)
        if not processed_reviews:
            return {'verdict': 'error', 'confidence': 0, 'error': 'ë¶„ì„í•  ë¦¬ë·° ì—†ìŒ'}
            
        return self.analyze_reviews(processed_reviews)

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--input', type=str)
    parser.add_argument('--output', type=str)
    parser.add_argument('--model', type=str, default='ai_models')
    args = parser.parse_args()
    
    try:
        if args.input:
            with open(args.input, 'r', encoding='utf-8') as f:
                data = json.load(f)
        else:
            data = json.load(sys.stdin)
        
        reviews = data.get('reviews', [])
        
        analyzer = ReviewAIAnalyzer(model_path=args.model)
        result = analyzer.run(reviews)
        
        output_data = {'success': True, 'result': result}
        
        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, ensure_ascii=False, indent=2)
        else:
            print(json.dumps(output_data, ensure_ascii=False))
            
    except Exception as e:
        error_data = {'success': False, 'error': str(e)}
        print(json.dumps(error_data, ensure_ascii=False))

if __name__ == "__main__":
    main()